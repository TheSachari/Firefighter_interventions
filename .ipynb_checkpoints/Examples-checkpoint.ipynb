{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a4286b-83a4-4f81-b9b1-aecfb71130a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import pickle\n",
    "from IPython import get_ipython\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb3a3c9-ea32-4be0-a174-491e77646798",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ec22b4-f6ae-4a71-96d2-fdbd39ea1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Month_sin', 'Month_cos', 'Hour_sin', 'Hour_cos', 'Day_sin', 'Day_cos',\n",
      "       'Coord X', 'Coord Y', 'Duration', 'Incident', 'Month', 'Day', 'Hour'],\n",
      "      dtype='object')\n",
      "Index(['Month_sin', 'Month_cos', 'Hour_sin', 'Hour_cos', 'Day_sin', 'Day_cos',\n",
      "       'Coord X', 'Coord Y', 'Duration', 'Incident'],\n",
      "      dtype='object')\n",
      "K [0]\n",
      "features 9\n",
      "{'d_in': np.int64(9), 'is_y_cond': True, 'num_classes': 56, 'rtdl_params': {'d_layers': [1024, 1024], 'dropout': 0.0}, 'dim_t': 128}\n",
      "mlp\n",
      "label embedding Embedding(56, 128)\n",
      "diffusion ready\n",
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "%run train.py --lr 0.0025 --layers 1024 --num_timesteps 1000 --is_y_cond --save_as 'dqn_test' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10582dc0-d140-4c06-9ebc-cce58564fb1b",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f9804-231c-4adc-8a8c-ce1e4d8079d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): # génère i datasets\n",
    "    print(\"iteration\", i)\n",
    "    filename = f\"df_fake_{i}.pkl\"\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        [\"python\", \"sample.py\", \n",
    "         \"--load_as\", 'dqn_test', \n",
    "         \"--save_sample_as\", filename, \n",
    "         \"--os_factor\", \"3\", \n",
    "         \"--to_keep\", \"40\", \n",
    "         \"--value_span\", \"100\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1  # pour forcer le flush ligne par ligne\n",
    "    )\n",
    "\n",
    "    # process.wait() # évite le lazy\n",
    "\n",
    "    line_count = 0\n",
    "    for line in process.stdout:\n",
    "        line_count += 1\n",
    "        if line_count % 50 == 0:\n",
    "            clear_output(wait=True)\n",
    "    \n",
    "        print(line.strip())\n",
    "\n",
    "    print(f\"--- {filename} done---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5827859-987d-4ce5-932d-549ca39adb4e",
   "metadata": {},
   "source": [
    "# Generate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356e36b-ddf6-497f-8ea3-c0b9f0dfdc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lister les fichiers samplés à concaténer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e1fc1-21be-492f-a751-4b5fe1ebf704",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%run generate_environment.py --sample_list df_fake_0.pkl df_fake_1.pkl df_fake_2.pkl df_fake_3.pkl df_fake_4.pkl df_fake_5.pkl df_fake_6.pkl df_fake_7.pkl df_fake_8.pkl df_fake_9.pkl --save_as \"df_pc_fake_10y.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48da321-09df-41e4-bd20-7fcd33c41dfd",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279de376-a88a-4b09-b188-06a5d3c2a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tarif_sent_disp = {\n",
    "                'v_sent': 0,\n",
    "                'v_sent_full': 0,\n",
    "                'v_degraded':0,\n",
    "                'cancelled':0,\n",
    "                'function_not_found':0,\n",
    "                'v1_not_sent_from_1st_station':0,\n",
    "                'v_not_found_in_last_station':0,\n",
    "                'z1_EPA_sent': 0,\n",
    "                'z1_FPT_sent': 0,\n",
    "                'z1_VSAV_sent': 0,\n",
    "                'VSAV_needed':0,\n",
    "                'FPT_needed':0,\n",
    "                'EPA_needed':0,\n",
    "                'VSAV_disp':10,\n",
    "                'FPT_disp':10,\n",
    "                'EPA_disp':10,\n",
    "                'skill_lvl':0\n",
    "                }\n",
    "\n",
    "os.chdir('./Reward_weights')\n",
    "\n",
    "with open(f\"rw_sent_disp.json\", \"w\") as f:\n",
    "        json.dump(dic_tarif_sent_disp, f)\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e445a53-f006-44dd-b988-6c08f3196786",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b09f53-c52a-4b66-b2ea-e5ac0f6c3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    \"python3\", \"-u\", \"simulation_start.py\",\n",
    "    \"--reward_weights\", f\"rw_sent_disp.json\",\n",
    "    \"--dataset\", \"df_pc_real.pkl\",\n",
    "    \"--start\", \"1\",\n",
    "    \"--end\", \"53088\",\n",
    "    \"--constraint_factor_veh\", \"3\",\n",
    "    \"--constraint_factor_ff\", \"1\",\n",
    "    \"--is_best\",\n",
    "    \"--save_metrics_as\", f\"sim_sent_disp_bst\"\n",
    "]\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "line_count = 0\n",
    "stdout_lines = deque(maxlen=5000)\n",
    "for line in process.stdout:\n",
    "    stdout_lines.append(line)\n",
    "    line_count += 1\n",
    "    if line_count % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42062e6-6f3d-491b-8bb6-0b292aaa8ee9",
   "metadata": {},
   "source": [
    "# Agent params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca2626-2379-4a64-91e9-e42d0189a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = 80\n",
    "train_seed = 41\n",
    "\n",
    "os.chdir(\"./Data\")\n",
    "\n",
    "\n",
    "hyper_params = {\"state_size\" : (action_size + 2) *40,\n",
    "                \"action_size\" : action_size,\n",
    "                \"layer_type\" : \"ff\", # noisy else ff\n",
    "                \"layer_size\" : 1024,\n",
    "                \"num_layers\" : 8,\n",
    "                \"use_batchnorm\" : True,\n",
    "                \"n_steps\" : 20, #5, 1, 50, 64\n",
    "                \"batch_size\" : 256, #512, 256, 64, 32, 16, 8\n",
    "                \"buffer_size\" : 100000, #100000, 128, 5000, 10000, 65 buffer_size > batch_size\n",
    "                \"update_every\" : 32, #1, 200, 500, 64, 32 Q updates\n",
    "                \"per\" : 1, # 0 for curiosity > 0, else 1, 2\n",
    "                \"rdm\" : 0, # only if not per\n",
    "                \"munchausen\" : 1, #1\n",
    "                \"curiosity\" : 0, #Adds intrinsic curiosity to the extrinsic reward. 0 - only reward/ no curiosity, \n",
    "                                                                                    #1 - reward and curiosity, \n",
    "                                                                                    #2 - only curiosity\n",
    "                \"curiosity_size\" : 1024,\n",
    "                \"lr\" : 1e-4, #1e-3, 5e-4, 5e-3, 1e-4\n",
    "                \"lr_dec\" : 1, #0, 1, 2, 3\n",
    "                \"entropy_tau\" : 0.03, #0.03, 0.05 idem #-  Munch param\n",
    "                \"entropy_tau_coeff\" : 1e-2, #1e-2 #-  Munch param\n",
    "                \"lo\" : -1, #-  Munch param\n",
    "                \"alpha\" : 0.9, #-  Munch param\n",
    "                \"gamma\" : 0.99,\n",
    "                \"tau\" : 0.005, #1e-2, 5e-3\n",
    "                \"N\" : 32,# Number of quantiles 32, 64\n",
    "                \"entropy_coeff\" : 0.001,\n",
    "                \"decay_update\" : 100,\n",
    "                \"device\" : str(device),\n",
    "                \"seed\" : train_seed}\n",
    "\n",
    "\n",
    "json.dump(hyper_params, open(\"hyper_params.json\", \"w\"))\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3d281-6f9e-4148-8aa5-71d35e5e532a",
   "metadata": {},
   "source": [
    "# Agent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06a390-a460-47b8-8db2-02fb5d9d00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"fqf\"\n",
    "years = \"10y\"\n",
    "\n",
    "cmd = [\n",
    "    \"python3\", \"-u\", \"agent_run.py\",\n",
    "    \"--model_name\", f\"agent_{model}_{years}\",\n",
    "    \"--agent_model\", model,\n",
    "    \"--hyper_params\", \"hyper_params.json\",\n",
    "    \"--reward_weights\", f\"rw_sent_disp.json\",\n",
    "    \"--dataset\", f\"df_pc_fake_{years}.pkl\",\n",
    "    \"--start\", \"1\",\n",
    "    \"--end\", \"530880\",\n",
    "    \"--eps_start\", \"1\",\n",
    "    \"--constraint_factor_veh\", \"3\",\n",
    "    \"--constraint_factor_ff\", \"1\",\n",
    "    \"--save_metrics_as\", f\"agent_metrics_{model}_{years}\",\n",
    "    \"--train\",\n",
    "\n",
    "]\n",
    "# \"--load\"\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    cmd,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "line_count = 0\n",
    "stdout_lines = deque(maxlen=5000)\n",
    "for line in process.stdout:\n",
    "    stdout_lines.append(line)\n",
    "    line_count += 1\n",
    "    if line_count % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6c47df-e9cf-4de8-90bc-f3caafd1978f",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d1dbb-e6e9-4ac1-b22d-ab3671bbb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./Plots\"\n",
    "\n",
    "data = {}\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        full_path = os.path.join(folder_path, file_name)\n",
    "        with open(full_path, \"rb\") as f:\n",
    "            d = pickle.load(f)\n",
    "            name = os.path.splitext(file_name)[0]\n",
    "            data[name] = d\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7ca27-5cc2-4259-a99e-be671170d7f4",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc964c-bc39-46b6-8467-02941d955416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%run plot_evo.py \\\n",
    "agent_metrics_v_degraded_r100_cf3_reward_real.npy \\\n",
    "sim_metrics_r100_cf3_reward_real.npy \\\n",
    "--interpolation 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
